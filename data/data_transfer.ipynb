{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7f869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Personal Finance Database Import Tool\n",
      "============================================================\n",
      "Started at: 2025-06-30 14:25:29.458689\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Personal Finance Database Import - Complete Data Migration\n",
    "# This notebook will import all data from data.xlsx into the personal_finance.db\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('data_import.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üöÄ Personal Finance Database Import Tool\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Started at: {datetime.now()}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa524b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 14:25:29,472 - INFO - ‚úÖ Database backup created: personal_finance_backup_20250630_142529.db\n",
      "2025-06-30 14:25:29,473 - INFO - ‚úÖ Connected to personal_finance.db\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: DATABASE CONNECTION AND BACKUP\n",
    "# =============================================================================\n",
    "\n",
    "def create_backup():\n",
    "    \"\"\"Create a backup of the current database\"\"\"\n",
    "    try:\n",
    "        db_path = 'personal_finance.db'\n",
    "        if os.path.exists(db_path):\n",
    "            backup_path = f'personal_finance_backup_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.db'\n",
    "            shutil.copy2(db_path, backup_path)\n",
    "            logger.info(f\"‚úÖ Database backup created: {backup_path}\")\n",
    "            return backup_path\n",
    "        else:\n",
    "            logger.info(\"‚ÑπÔ∏è No existing database found - fresh import\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error creating backup: {e}\")\n",
    "        raise\n",
    "\n",
    "def connect_database():\n",
    "    \"\"\"Connect to the database and return connection\"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect('personal_finance.db')\n",
    "        logger.info(\"‚úÖ Connected to personal_finance.db\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error connecting to database: {e}\")\n",
    "        raise\n",
    "\n",
    "# Create backup and connect\n",
    "backup_file = create_backup()\n",
    "conn = connect_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28e961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä DATABASE STRUCTURE ANALYSIS\n",
      "----------------------------------------\n",
      "\n",
      "üîç Table: transactions\n",
      "   Rows: 5878\n",
      "   Columns:\n",
      "     - id: INTEGER optional (PK)\n",
      "     - account_name: TEXT REQUIRED\n",
      "     - date: DATE REQUIRED\n",
      "     - description: TEXT REQUIRED\n",
      "     - amount: DECIMAL(10,2) REQUIRED\n",
      "     - sub_category: TEXT optional\n",
      "     - category: TEXT REQUIRED\n",
      "     - type: TEXT REQUIRED\n",
      "     - owner: TEXT REQUIRED\n",
      "     - is_business: BOOLEAN optional\n",
      "     - debt_payment_id: INTEGER optional\n",
      "     - created_at: TIMESTAMP optional\n",
      "     - updated_at: TIMESTAMP optional\n",
      "     - is_active: BOOLEAN optional\n",
      "\n",
      "üîç Table: sqlite_sequence\n",
      "   Rows: 5\n",
      "   Columns:\n",
      "     - name:  optional\n",
      "     - seq:  optional\n",
      "\n",
      "üîç Table: budget_templates\n",
      "   Rows: 23\n",
      "   Columns:\n",
      "     - id: INTEGER optional (PK)\n",
      "     - category: TEXT REQUIRED\n",
      "     - budget_amount: DECIMAL(10,2) REQUIRED\n",
      "     - notes: TEXT optional\n",
      "     - is_active: BOOLEAN optional\n",
      "     - created_at: TIMESTAMP optional\n",
      "     - updated_at: TIMESTAMP optional\n",
      "\n",
      "üîç Table: unexpected_expenses\n",
      "   Rows: 1\n",
      "   Columns:\n",
      "     - id: INTEGER optional (PK)\n",
      "     - category: TEXT REQUIRED\n",
      "     - month: INTEGER REQUIRED\n",
      "     - year: INTEGER REQUIRED\n",
      "     - amount: DECIMAL(10,2) REQUIRED\n",
      "     - description: TEXT REQUIRED\n",
      "     - is_active: BOOLEAN optional\n",
      "     - created_at: TIMESTAMP optional\n",
      "     - updated_at: TIMESTAMP optional\n",
      "\n",
      "üîç Table: monthly_budgets\n",
      "   Rows: 0\n",
      "   Columns:\n",
      "     - id: INTEGER optional (PK)\n",
      "     - category: TEXT REQUIRED\n",
      "     - month: INTEGER REQUIRED\n",
      "     - year: INTEGER REQUIRED\n",
      "     - budget_amount: DECIMAL(10,2) REQUIRED\n",
      "     - notes: TEXT optional\n",
      "     - created_at: TIMESTAMP optional\n",
      "     - updated_at: TIMESTAMP optional\n",
      "\n",
      "üîç Table: debt_accounts\n",
      "   Rows: 5\n",
      "   Columns:\n",
      "     - id: INTEGER optional (PK)\n",
      "     - name: TEXT REQUIRED\n",
      "     - debt_type: TEXT REQUIRED\n",
      "     - original_balance: DECIMAL(10,2) REQUIRED\n",
      "     - current_balance: DECIMAL(10,2) REQUIRED\n",
      "     - interest_rate: DECIMAL(5,4) optional\n",
      "     - minimum_payment: DECIMAL(10,2) optional\n",
      "     - due_date: INTEGER optional\n",
      "     - owner: TEXT REQUIRED\n",
      "     - category: TEXT REQUIRED\n",
      "     - account_number_last4: TEXT optional\n",
      "     - is_active: BOOLEAN optional\n",
      "     - created_at: TIMESTAMP optional\n",
      "     - updated_at: TIMESTAMP optional\n",
      "\n",
      "üîç Table: debt_payments\n",
      "   Rows: 2\n",
      "   Columns:\n",
      "     - id: INTEGER optional (PK)\n",
      "     - debt_account_id: INTEGER REQUIRED\n",
      "     - payment_amount: DECIMAL(10,2) REQUIRED\n",
      "     - principal_amount: DECIMAL(10,2) optional\n",
      "     - interest_amount: DECIMAL(10,2) optional\n",
      "     - payment_date: DATE REQUIRED\n",
      "     - balance_after_payment: DECIMAL(10,2) REQUIRED\n",
      "     - payment_type: TEXT optional\n",
      "     - notes: TEXT optional\n",
      "\n",
      "üîç Table: business_revenue\n",
      "   Rows: 0\n",
      "   Columns:\n",
      "     - id: INTEGER optional (PK)\n",
      "     - date: DATE REQUIRED\n",
      "     - description: TEXT REQUIRED\n",
      "     - amount: DECIMAL(10,2) REQUIRED\n",
      "     - source: TEXT optional\n",
      "     - category: TEXT optional\n",
      "     - owner: TEXT REQUIRED\n",
      "     - invoice_number: TEXT optional\n",
      "     - created_at: TIMESTAMP optional\n",
      "\n",
      "üîç Table: business_transactions\n",
      "   Rows: 0\n",
      "   Columns:\n",
      "     - id: INTEGER optional (PK)\n",
      "     - date: DATE REQUIRED\n",
      "     - description: TEXT REQUIRED\n",
      "     - amount: DECIMAL(10,2) REQUIRED\n",
      "     - category: TEXT REQUIRED\n",
      "     - sub_category: TEXT optional\n",
      "     - transaction_type: TEXT REQUIRED\n",
      "     - account_name: TEXT REQUIRED\n",
      "     - vendor: TEXT optional\n",
      "     - invoice_number: TEXT optional\n",
      "     - tax_deductible: BOOLEAN optional\n",
      "     - notes: TEXT optional\n",
      "     - created_at: TIMESTAMP optional\n",
      "     - updated_at: TIMESTAMP optional\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: ANALYZE DATABASE STRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_database_structure(conn):\n",
    "    \"\"\"Analyze the current database structure\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(\"\\nüìä DATABASE STRUCTURE ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Get all tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    tables = cursor.fetchall()\n",
    "    \n",
    "    structure_info = {}\n",
    "    \n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        print(f\"\\nüîç Table: {table_name}\")\n",
    "        \n",
    "        # Get table info\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        columns = cursor.fetchall()\n",
    "        \n",
    "        # Get row count\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "        row_count = cursor.fetchone()[0]\n",
    "        \n",
    "        print(f\"   Rows: {row_count}\")\n",
    "        print(\"   Columns:\")\n",
    "        \n",
    "        table_columns = []\n",
    "        for col in columns:\n",
    "            col_info = {\n",
    "                'name': col[1],\n",
    "                'type': col[2],\n",
    "                'not_null': bool(col[3]),\n",
    "                'default': col[4],\n",
    "                'primary_key': bool(col[5])\n",
    "            }\n",
    "            table_columns.append(col_info)\n",
    "            \n",
    "            required = \"REQUIRED\" if col_info['not_null'] else \"optional\"\n",
    "            pk = \" (PK)\" if col_info['primary_key'] else \"\"\n",
    "            print(f\"     - {col_info['name']}: {col_info['type']} {required}{pk}\")\n",
    "        \n",
    "        structure_info[table_name] = {\n",
    "            'columns': table_columns,\n",
    "            'row_count': row_count\n",
    "        }\n",
    "    \n",
    "    return structure_info\n",
    "\n",
    "# Analyze current structure\n",
    "db_structure = analyze_database_structure(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51fc0009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà EXCEL DATA ANALYSIS\n",
      "----------------------------------------\n",
      "üìã Found 1 sheets: ['Transactions']\n",
      "\n",
      "üîç Analyzing sheet: Transactions\n",
      "   Rows: 6044\n",
      "   Columns: 8\n",
      "   Column names:\n",
      "     - Account Name\n",
      "     - Date\n",
      "     - Description\n",
      "     - Amount\n",
      "     - Sub Category\n",
      "     - Category\n",
      "     - Type\n",
      "     - Owner\n",
      "   Missing values:\n",
      "     - Date: 1 missing\n",
      "     - Description: 21 missing\n",
      "     - Sub Category: 1 missing\n",
      "     - Category: 1 missing\n",
      "     - Type: 1 missing\n",
      "     - Owner: 1 missing\n",
      "   Sample data (first 3 rows):\n",
      "Account Name       Date Description Amount  Sub Category        Category  Type    Owner\n",
      "     Venture 2025-06-28        HEB    53.8     Groceries Living Expenses Needs Suricata\n",
      "     Venture 2025-06-28     Peacock   8.65 Subscriptions   Subscriptions Wants Suricata\n",
      "     Venture 2025-06-27        HEB   42.87     Groceries Living Expenses Needs Suricata\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: LOAD AND ANALYZE EXCEL DATA\n",
    "# =============================================================================\n",
    "\n",
    "def load_excel_data():\n",
    "    \"\"\"Load and analyze the Excel data\"\"\"\n",
    "    try:\n",
    "        print(\"\\nüìà EXCEL DATA ANALYSIS\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Load the Excel file\n",
    "        excel_file = 'data.xlsm'\n",
    "        if not os.path.exists(excel_file):\n",
    "            raise FileNotFoundError(f\"Excel file not found: {excel_file}\")\n",
    "        \n",
    "        # Get all sheet names\n",
    "        xl_file = pd.ExcelFile(excel_file)\n",
    "        sheet_names = xl_file.sheet_names\n",
    "        print(f\"üìã Found {len(sheet_names)} sheets: {sheet_names}\")\n",
    "        \n",
    "        sheets_data = {}\n",
    "        \n",
    "        for sheet_name in sheet_names:\n",
    "            print(f\"\\nüîç Analyzing sheet: {sheet_name}\")\n",
    "            df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "            \n",
    "            print(f\"   Rows: {len(df)}\")\n",
    "            print(f\"   Columns: {len(df.columns)}\")\n",
    "            print(\"   Column names:\")\n",
    "            for col in df.columns:\n",
    "                print(f\"     - {col}\")\n",
    "            \n",
    "            # Check for missing values\n",
    "            missing_data = df.isnull().sum()\n",
    "            if missing_data.sum() > 0:\n",
    "                print(\"   Missing values:\")\n",
    "                for col, missing_count in missing_data.items():\n",
    "                    if missing_count > 0:\n",
    "                        print(f\"     - {col}: {missing_count} missing\")\n",
    "            \n",
    "            # Sample data\n",
    "            print(\"   Sample data (first 3 rows):\")\n",
    "            print(df.head(3).to_string(index=False))\n",
    "            \n",
    "            sheets_data[sheet_name] = df\n",
    "        \n",
    "        return sheets_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error loading Excel data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load Excel data\n",
    "excel_data = load_excel_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea80e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 14:25:29,961 - INFO - Cleared transactions: 5878 rows deleted\n",
      "2025-06-30 14:25:29,962 - INFO - Cleared budget_templates: 23 rows deleted\n",
      "2025-06-30 14:25:29,963 - INFO - Cleared unexpected_expenses: 1 rows deleted\n",
      "2025-06-30 14:25:29,963 - INFO - Cleared monthly_budgets: 0 rows deleted\n",
      "2025-06-30 14:25:29,964 - INFO - Cleared debt_accounts: 5 rows deleted\n",
      "2025-06-30 14:25:29,964 - INFO - Cleared debt_payments: 2 rows deleted\n",
      "2025-06-30 14:25:29,965 - INFO - Cleared business_revenue: 0 rows deleted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßπ CLEARING EXISTING DATA\n",
      "----------------------------------------\n",
      "‚úÖ Cleared transactions: 5878 rows deleted\n",
      "‚úÖ Cleared budget_templates: 23 rows deleted\n",
      "‚úÖ Cleared unexpected_expenses: 1 rows deleted\n",
      "‚úÖ Cleared monthly_budgets: 0 rows deleted\n",
      "‚úÖ Cleared debt_accounts: 5 rows deleted\n",
      "‚úÖ Cleared debt_payments: 2 rows deleted\n",
      "‚úÖ Cleared business_revenue: 0 rows deleted\n",
      "‚úÖ All existing data cleared\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: CLEAR EXISTING DATA\n",
    "# =============================================================================\n",
    "\n",
    "def clear_existing_data(conn):\n",
    "    \"\"\"Clear existing data from all tables\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(\"\\nüßπ CLEARING EXISTING DATA\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    tables_to_clear = [\n",
    "        'transactions',\n",
    "        'budget_templates', \n",
    "        'unexpected_expenses',\n",
    "        'monthly_budgets',\n",
    "        'debt_accounts',\n",
    "        'debt_payments',\n",
    "        'business_revenue'\n",
    "    ]\n",
    "    \n",
    "    for table in tables_to_clear:\n",
    "        try:\n",
    "            # Check if table exists\n",
    "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name=?\", (table,))\n",
    "            if cursor.fetchone():\n",
    "                # Get count before deletion\n",
    "                cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "                count_before = cursor.fetchone()[0]\n",
    "                \n",
    "                # Clear the table\n",
    "                cursor.execute(f\"DELETE FROM {table}\")\n",
    "                rows_deleted = cursor.rowcount\n",
    "                \n",
    "                # Reset auto-increment if it's the transactions table\n",
    "                if table == 'transactions':\n",
    "                    cursor.execute(\"DELETE FROM sqlite_sequence WHERE name='transactions'\")\n",
    "                \n",
    "                print(f\"‚úÖ Cleared {table}: {rows_deleted} rows deleted\")\n",
    "                logger.info(f\"Cleared {table}: {rows_deleted} rows deleted\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Table {table} not found\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error clearing {table}: {e}\")\n",
    "            print(f\"‚ùå Error clearing {table}: {e}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"‚úÖ All existing data cleared\")\n",
    "\n",
    "# Clear existing data\n",
    "clear_existing_data(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27781ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: DYNAMIC DATA MAPPING BASED ON ACTUAL EXCEL STRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "def detect_excel_structure(excel_data):\n",
    "    \"\"\"Automatically detect Excel structure and create mapping\"\"\"\n",
    "    \n",
    "    print(\"\\nüîç DETECTING EXCEL STRUCTURE\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Find the transactions sheet\n",
    "    transactions_sheet = None\n",
    "    if 'Transactions' in excel_data:\n",
    "        transactions_sheet = 'Transactions'\n",
    "        print(f\"‚úÖ Found transactions sheet: {transactions_sheet}\")\n",
    "    elif 'Sheet1' in excel_data:\n",
    "        transactions_sheet = 'Sheet1'\n",
    "        print(f\"‚úÖ Found default sheet: {transactions_sheet}\")\n",
    "    else:\n",
    "        # Use the first sheet\n",
    "        transactions_sheet = list(excel_data.keys())[0]\n",
    "        print(f\"‚ö†Ô∏è Using first available sheet: {transactions_sheet}\")\n",
    "    \n",
    "    df = excel_data[transactions_sheet]\n",
    "    excel_columns = list(df.columns)\n",
    "    print(f\"üìã Available columns: {excel_columns}\")\n",
    "    \n",
    "    # Smart column detection\n",
    "    column_mapping = {}\n",
    "    \n",
    "    # Date column detection\n",
    "    date_patterns = ['date', 'Date', 'DATE', 'transaction_date', 'Transaction Date']\n",
    "    for pattern in date_patterns:\n",
    "        if pattern in excel_columns:\n",
    "            column_mapping['date'] = pattern\n",
    "            break\n",
    "    \n",
    "    # Description column detection\n",
    "    desc_patterns = ['description', 'Description', 'DESC', 'details', 'Details', 'transaction', 'Transaction']\n",
    "    for pattern in desc_patterns:\n",
    "        if pattern in excel_columns:\n",
    "            column_mapping['description'] = pattern\n",
    "            break\n",
    "    \n",
    "    # Amount column detection\n",
    "    amount_patterns = ['amount', 'Amount', 'AMOUNT', 'value', 'Value', 'transaction_amount']\n",
    "    for pattern in amount_patterns:\n",
    "        if pattern in excel_columns:\n",
    "            column_mapping['amount'] = pattern\n",
    "            break\n",
    "    \n",
    "    # Category column detection\n",
    "    category_patterns = ['category', 'Category', 'CATEGORY', 'type', 'Type']\n",
    "    for pattern in category_patterns:\n",
    "        if pattern in excel_columns:\n",
    "            column_mapping['category'] = pattern\n",
    "            break\n",
    "    \n",
    "    # Sub-category detection\n",
    "    subcategory_patterns = ['sub_category', 'Sub Category', 'subcategory', 'Subcategory', 'sub category']\n",
    "    for pattern in subcategory_patterns:\n",
    "        if pattern in excel_columns:\n",
    "            column_mapping['sub_category'] = pattern\n",
    "            break\n",
    "    \n",
    "    # Transaction type detection\n",
    "    type_patterns = ['type', 'Type', 'transaction_type', 'Transaction Type', 'expense_type']\n",
    "    for pattern in type_patterns:\n",
    "        if pattern in excel_columns:\n",
    "            column_mapping['type'] = pattern\n",
    "            break\n",
    "    \n",
    "    # Owner detection\n",
    "    owner_patterns = ['owner', 'Owner', 'OWNER', 'person', 'Person', 'user', 'User']\n",
    "    for pattern in owner_patterns:\n",
    "        if pattern in excel_columns:\n",
    "            column_mapping['owner'] = pattern\n",
    "            break\n",
    "    \n",
    "    # Account detection\n",
    "    account_patterns = ['account', 'Account', 'ACCOUNT', 'account_name', 'Account Name', 'bank', 'Bank']\n",
    "    for pattern in account_patterns:\n",
    "        if pattern in excel_columns:\n",
    "            column_mapping['account_name'] = pattern\n",
    "            break\n",
    "    \n",
    "    # Business flag detection\n",
    "    business_patterns = ['business', 'Business', 'is_business', 'Is Business', 'girasoul', 'Girasoul']\n",
    "    for pattern in business_patterns:\n",
    "        if pattern in excel_columns:\n",
    "            column_mapping['is_business'] = pattern\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nüìä Detected column mapping:\")\n",
    "    for db_col, excel_col in column_mapping.items():\n",
    "        print(f\"   {db_col} -> {excel_col}\")\n",
    "    \n",
    "    return transactions_sheet, column_mapping\n",
    "\n",
    "def create_data_mapping(excel_data):\n",
    "    \"\"\"Create mapping between Excel columns and database columns\"\"\"\n",
    "    \n",
    "    # Detect structure automatically\n",
    "    sheet_name, column_mapping = detect_excel_structure(excel_data)\n",
    "    \n",
    "    mapping = {\n",
    "        'transactions': {\n",
    "            'excel_sheet': sheet_name,\n",
    "            'column_mapping': column_mapping,\n",
    "            'transformations': {\n",
    "                'date': lambda x: pd.to_datetime(x).date() if pd.notna(x) else None,\n",
    "                'amount': lambda x: float(x) if pd.notna(x) else 0.0,\n",
    "                'is_business': lambda x: bool(x) if pd.notna(x) and str(x).lower() in ['true', '1', 'yes', 'y'] else False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "def transform_data_for_import(excel_data, mapping):\n",
    "    \"\"\"Transform Excel data for database import\"\"\"\n",
    "    \n",
    "    print(\"\\nüîÑ DATA TRANSFORMATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    transformed_data = {}\n",
    "    \n",
    "    for table_name, config in mapping.items():\n",
    "        print(f\"\\nüìã Transforming data for: {table_name}\")\n",
    "        \n",
    "        sheet_name = config['excel_sheet']\n",
    "        if sheet_name not in excel_data:\n",
    "            print(f\"‚ö†Ô∏è Sheet {sheet_name} not found in Excel data\")\n",
    "            continue\n",
    "        \n",
    "        df = excel_data[sheet_name].copy()\n",
    "        print(f\"   Source rows: {len(df)}\")\n",
    "        \n",
    "        # Apply column mapping\n",
    "        column_mapping = config['column_mapping']\n",
    "        available_columns = [col for col in column_mapping.values() if col in df.columns]\n",
    "        \n",
    "        if not available_columns:\n",
    "            print(f\"   ‚ùå No mapped columns found in Excel data\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"   ‚úÖ Available columns: {available_columns}\")\n",
    "        \n",
    "        # Create new DataFrame with mapped columns\n",
    "        df_mapped = pd.DataFrame()\n",
    "        \n",
    "        for db_col, excel_col in column_mapping.items():\n",
    "            if excel_col in df.columns:\n",
    "                df_mapped[db_col] = df[excel_col]\n",
    "                print(f\"   ‚úÖ Mapped: {excel_col} -> {db_col}\")\n",
    "        \n",
    "        # Apply transformations\n",
    "        transformations = config.get('transformations', {})\n",
    "        for col, transform_func in transformations.items():\n",
    "            if col in df_mapped.columns:\n",
    "                try:\n",
    "                    df_mapped[col] = df_mapped[col].apply(transform_func)\n",
    "                    print(f\"   ‚úÖ Transformed column: {col}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error transforming {col}: {e}\")\n",
    "        \n",
    "        # Add required fields that might be missing\n",
    "        if table_name == 'transactions':\n",
    "            # Add timestamps if not present\n",
    "            if 'created_at' not in df_mapped.columns:\n",
    "                df_mapped['created_at'] = datetime.utcnow().isoformat()\n",
    "            if 'updated_at' not in df_mapped.columns:\n",
    "                df_mapped['updated_at'] = datetime.utcnow().isoformat()\n",
    "            if 'is_active' not in df_mapped.columns:\n",
    "                df_mapped['is_active'] = 1\n",
    "            \n",
    "            # Ensure required fields have defaults\n",
    "            if 'debt_payment_id' not in df_mapped.columns:\n",
    "                df_mapped['debt_payment_id'] = None\n",
    "        \n",
    "        # Remove rows with missing critical data\n",
    "        initial_count = len(df_mapped)\n",
    "        required_fields = ['date', 'description', 'amount']\n",
    "        available_required = [field for field in required_fields if field in df_mapped.columns]\n",
    "        \n",
    "        if available_required:\n",
    "            df_mapped = df_mapped.dropna(subset=available_required)\n",
    "            final_count = len(df_mapped)\n",
    "            \n",
    "            if initial_count != final_count:\n",
    "                print(f\"   ‚ö†Ô∏è Dropped {initial_count - final_count} rows with missing required data\")\n",
    "        \n",
    "        print(f\"   ‚úÖ Final rows for import: {len(df_mapped)}\")\n",
    "        \n",
    "        # Show sample of transformed data\n",
    "        if len(df_mapped) > 0:\n",
    "            print(f\"   üìä Sample transformed data:\")\n",
    "            print(df_mapped.head(2).to_string(index=False))\n",
    "        \n",
    "        transformed_data[table_name] = df_mapped\n",
    "    \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8356408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 6: IMPORT DATA WITH PROGRESS TRACKING\n",
    "# =============================================================================\n",
    "\n",
    "def import_data_with_progress(conn, transformed_data):\n",
    "    \"\"\"Import data with detailed progress tracking\"\"\"\n",
    "    \n",
    "    print(\"\\nüì• IMPORTING DATA\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    import_results = {}\n",
    "    \n",
    "    for table_name, df in transformed_data.items():\n",
    "        print(f\"\\nüìã Importing to {table_name}\")\n",
    "        \n",
    "        try:\n",
    "            total_rows = len(df)\n",
    "            if total_rows == 0:\n",
    "                print(f\"   ‚ö†Ô∏è No data to import for {table_name}\")\n",
    "                import_results[table_name] = {'total': 0, 'imported': 0, 'errors': 0}\n",
    "                continue\n",
    "                \n",
    "            batch_size = 100\n",
    "            imported_count = 0\n",
    "            error_count = 0\n",
    "            \n",
    "            print(f\"   Total rows to import: {total_rows}\")\n",
    "            print(f\"   Columns to import: {list(df.columns)}\")\n",
    "            \n",
    "            # Import in batches\n",
    "            for start_idx in range(0, total_rows, batch_size):\n",
    "                end_idx = min(start_idx + batch_size, total_rows)\n",
    "                batch_df = df.iloc[start_idx:end_idx]\n",
    "                \n",
    "                try:\n",
    "                    # Insert batch\n",
    "                    batch_df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "                    imported_count += len(batch_df)\n",
    "                    \n",
    "                    # Progress update\n",
    "                    progress = (imported_count / total_rows) * 100\n",
    "                    print(f\"   Progress: {imported_count}/{total_rows} ({progress:.1f}%)\")\n",
    "                    \n",
    "                    # Commit every 10 batches\n",
    "                    if (start_idx // batch_size) % 10 == 0:\n",
    "                        conn.commit()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += len(batch_df)\n",
    "                    logger.error(f\"Error importing batch {start_idx}-{end_idx} to {table_name}: {e}\")\n",
    "                    print(f\"   ‚ùå Error in batch {start_idx}-{end_idx}: {e}\")\n",
    "                    \n",
    "                    # Try individual rows in failed batch\n",
    "                    for idx, row in batch_df.iterrows():\n",
    "                        try:\n",
    "                            row_df = pd.DataFrame([row])\n",
    "                            row_df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "                            imported_count += 1\n",
    "                            error_count -= 1\n",
    "                        except Exception as row_error:\n",
    "                            logger.error(f\"Error importing row {idx}: {row_error}\")\n",
    "                            print(f\"   ‚ùå Failed row {idx}: {row_error}\")\n",
    "            \n",
    "            # Final commit\n",
    "            conn.commit()\n",
    "            \n",
    "            # Final results\n",
    "            print(f\"   ‚úÖ Import completed:\")\n",
    "            print(f\"      - Successful: {imported_count}\")\n",
    "            print(f\"      - Errors: {error_count}\")\n",
    "            print(f\"      - Success rate: {(imported_count/total_rows*100):.1f}%\")\n",
    "            \n",
    "            import_results[table_name] = {\n",
    "                'total': total_rows,\n",
    "                'imported': imported_count,\n",
    "                'errors': error_count\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error importing {table_name}: {e}\")\n",
    "            print(f\"‚ùå Error importing {table_name}: {e}\")\n",
    "            import_results[table_name] = {\n",
    "                'total': len(df) if 'df' in locals() else 0,\n",
    "                'imported': 0,\n",
    "                'errors': len(df) if 'df' in locals() else 0\n",
    "            }\n",
    "    \n",
    "    return import_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bca6ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ EXECUTING IMPORT\n",
      "----------------------------------------\n",
      "\n",
      "üîç DETECTING EXCEL STRUCTURE\n",
      "----------------------------------------\n",
      "‚úÖ Found transactions sheet: Transactions\n",
      "üìã Available columns: ['Account Name', 'Date', 'Description', 'Amount', 'Sub Category', 'Category', 'Type', 'Owner']\n",
      "\n",
      "üìä Detected column mapping:\n",
      "   date -> Date\n",
      "   description -> Description\n",
      "   amount -> Amount\n",
      "   category -> Category\n",
      "   sub_category -> Sub Category\n",
      "   type -> Type\n",
      "   owner -> Owner\n",
      "   account_name -> Account Name\n",
      "\n",
      "üîÑ DATA TRANSFORMATION\n",
      "----------------------------------------\n",
      "\n",
      "üìã Transforming data for: transactions\n",
      "   Source rows: 6044\n",
      "   ‚úÖ Available columns: ['Date', 'Description', 'Amount', 'Category', 'Sub Category', 'Type', 'Owner', 'Account Name']\n",
      "   ‚úÖ Mapped: Date -> date\n",
      "   ‚úÖ Mapped: Description -> description\n",
      "   ‚úÖ Mapped: Amount -> amount\n",
      "   ‚úÖ Mapped: Category -> category\n",
      "   ‚úÖ Mapped: Sub Category -> sub_category\n",
      "   ‚úÖ Mapped: Type -> type\n",
      "   ‚úÖ Mapped: Owner -> owner\n",
      "   ‚úÖ Mapped: Account Name -> account_name\n",
      "   ‚úÖ Transformed column: date\n",
      "   ‚ùå Error transforming amount: could not convert string to float: 'MCT'\n",
      "   ‚ö†Ô∏è Dropped 21 rows with missing required data\n",
      "   ‚úÖ Final rows for import: 6023\n",
      "   üìä Sample transformed data:\n",
      "      date description amount        category  sub_category  type    owner account_name                 created_at                 updated_at  is_active debt_payment_id\n",
      "2025-06-28        HEB    53.8 Living Expenses     Groceries Needs Suricata      Venture 2025-06-30T19:25:30.033306 2025-06-30T19:25:30.033306          1            None\n",
      "2025-06-28     Peacock   8.65   Subscriptions Subscriptions Wants Suricata      Venture 2025-06-30T19:25:30.033306 2025-06-30T19:25:30.033306          1            None\n",
      "\n",
      "üì• IMPORTING DATA\n",
      "----------------------------------------\n",
      "\n",
      "üìã Importing to transactions\n",
      "   Total rows to import: 6023\n",
      "   Columns to import: ['date', 'description', 'amount', 'category', 'sub_category', 'type', 'owner', 'account_name', 'created_at', 'updated_at', 'is_active', 'debt_payment_id']\n",
      "   Progress: 100/6023 (1.7%)\n",
      "   Progress: 200/6023 (3.3%)\n",
      "   Progress: 300/6023 (5.0%)\n",
      "   Progress: 400/6023 (6.6%)\n",
      "   Progress: 500/6023 (8.3%)\n",
      "   Progress: 600/6023 (10.0%)\n",
      "   Progress: 700/6023 (11.6%)\n",
      "   Progress: 800/6023 (13.3%)\n",
      "   Progress: 900/6023 (14.9%)\n",
      "   Progress: 1000/6023 (16.6%)\n",
      "   Progress: 1100/6023 (18.3%)\n",
      "   Progress: 1200/6023 (19.9%)\n",
      "   Progress: 1300/6023 (21.6%)\n",
      "   Progress: 1400/6023 (23.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELCACAZ\\AppData\\Local\\Temp\\ipykernel_1348\\3538824744.py:171: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  df_mapped['created_at'] = datetime.utcnow().isoformat()\n",
      "C:\\Users\\ELCACAZ\\AppData\\Local\\Temp\\ipykernel_1348\\3538824744.py:173: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  df_mapped['updated_at'] = datetime.utcnow().isoformat()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Progress: 1500/6023 (24.9%)\n",
      "   Progress: 1600/6023 (26.6%)\n",
      "   Progress: 1700/6023 (28.2%)\n",
      "   Progress: 1800/6023 (29.9%)\n",
      "   Progress: 1900/6023 (31.5%)\n",
      "   Progress: 2000/6023 (33.2%)\n",
      "   Progress: 2100/6023 (34.9%)\n",
      "   Progress: 2200/6023 (36.5%)\n",
      "   Progress: 2300/6023 (38.2%)\n",
      "   Progress: 2400/6023 (39.8%)\n",
      "   Progress: 2500/6023 (41.5%)\n",
      "   Progress: 2600/6023 (43.2%)\n",
      "   Progress: 2700/6023 (44.8%)\n",
      "   Progress: 2800/6023 (46.5%)\n",
      "   Progress: 2900/6023 (48.1%)\n",
      "   Progress: 3000/6023 (49.8%)\n",
      "   Progress: 3100/6023 (51.5%)\n",
      "   Progress: 3200/6023 (53.1%)\n",
      "   Progress: 3300/6023 (54.8%)\n",
      "   Progress: 3400/6023 (56.5%)\n",
      "   Progress: 3500/6023 (58.1%)\n",
      "   Progress: 3600/6023 (59.8%)\n",
      "   Progress: 3700/6023 (61.4%)\n",
      "   Progress: 3800/6023 (63.1%)\n",
      "   Progress: 3900/6023 (64.8%)\n",
      "   Progress: 4000/6023 (66.4%)\n",
      "   Progress: 4100/6023 (68.1%)\n",
      "   Progress: 4200/6023 (69.7%)\n",
      "   Progress: 4300/6023 (71.4%)\n",
      "   Progress: 4400/6023 (73.1%)\n",
      "   Progress: 4500/6023 (74.7%)\n",
      "   Progress: 4600/6023 (76.4%)\n",
      "   Progress: 4700/6023 (78.0%)\n",
      "   Progress: 4800/6023 (79.7%)\n",
      "   Progress: 4900/6023 (81.4%)\n",
      "   Progress: 5000/6023 (83.0%)\n",
      "   Progress: 5100/6023 (84.7%)\n",
      "   Progress: 5200/6023 (86.3%)\n",
      "   Progress: 5300/6023 (88.0%)\n",
      "   Progress: 5400/6023 (89.7%)\n",
      "   Progress: 5500/6023 (91.3%)\n",
      "   Progress: 5600/6023 (93.0%)\n",
      "   Progress: 5700/6023 (94.6%)\n",
      "   Progress: 5800/6023 (96.3%)\n",
      "   Progress: 5900/6023 (98.0%)\n",
      "   Progress: 6000/6023 (99.6%)\n",
      "   Progress: 6023/6023 (100.0%)\n",
      "   ‚úÖ Import completed:\n",
      "      - Successful: 6023\n",
      "      - Errors: 0\n",
      "      - Success rate: 100.0%\n",
      "\n",
      "üìä IMPORT SUMMARY\n",
      "----------------------------------------\n",
      "transactions:\n",
      "  Total: 6023\n",
      "  Imported: 6023\n",
      "  Errors: 0\n",
      "  Success Rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 7: EXECUTE IMPORT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüöÄ EXECUTING IMPORT\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    # Create the mapping configuration\n",
    "    mapping = create_data_mapping(excel_data)\n",
    "    \n",
    "    # Transform the Excel data\n",
    "    transformed_data = transform_data_for_import(excel_data, mapping)\n",
    "    \n",
    "    # Import with progress tracking\n",
    "    import_results = import_data_with_progress(conn, transformed_data)\n",
    "    \n",
    "    print(\"\\nüìä IMPORT SUMMARY\")\n",
    "    print(\"-\" * 40)\n",
    "    for table, results in import_results.items():\n",
    "        print(f\"{table}:\")\n",
    "        print(f\"  Total: {results['total']}\")\n",
    "        print(f\"  Imported: {results['imported']}\")\n",
    "        print(f\"  Errors: {results['errors']}\")\n",
    "        success_rate = (results['imported'] / results['total'] * 100) if results['total'] > 0 else 0\n",
    "        print(f\"  Success Rate: {success_rate:.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Error during import execution: {e}\")\n",
    "    print(f\"‚ùå Error during import execution: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa77afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ IMPORT VALIDATION\n",
      "----------------------------------------\n",
      "üìä Total transactions imported: 6023\n",
      "üìÖ Date range: 2022-01-03 to 2025-06-30\n",
      "üìÇ Unique categories: 23\n",
      "üë• Unique owners: 3\n",
      "‚ö†Ô∏è Missing descriptions: 0\n",
      "‚ö†Ô∏è Missing categories: 0\n",
      "\n",
      "üìã Sample imported data (latest 5 transactions):\n",
      "   2025-06-30 | Samba's Karina | $44 | Business\n",
      "   2025-06-30 | venmo | $70 | Discretionary\n",
      "   2025-06-30 | Girasoul | $-323.69 | Business\n",
      "   2025-06-29 | Meta Publicity | $25 | Business\n",
      "   2025-06-28 | HEB  | $53.8 | Living Expenses\n",
      "\n",
      "üí∞ POPULATING BUDGET TEMPLATES\n",
      "----------------------------------------\n",
      "üìÇ Found 23 unique categories\n",
      "   ‚úÖ Created budget template: Argentina\n",
      "   ‚úÖ Created budget template: Beauty\n",
      "   ‚úÖ Created budget template: Business\n",
      "   ‚úÖ Created budget template: Charity\n",
      "   ‚úÖ Created budget template: Debt\n",
      "   ‚úÖ Created budget template: Dining Out\n",
      "   ‚úÖ Created budget template: Discretionary\n",
      "   ‚úÖ Created budget template: Dogs\n",
      "   ‚úÖ Created budget template: Gifts\n",
      "   ‚úÖ Created budget template: Government\n",
      "   ‚úÖ Created budget template: Health\n",
      "   ‚úÖ Created budget template: Home\n",
      "   ‚úÖ Created budget template: Learning\n",
      "   ‚úÖ Created budget template: Living Expenses\n",
      "   ‚úÖ Created budget template: Medical\n",
      "   ‚úÖ Created budget template: Moving\n",
      "   ‚úÖ Created budget template: Savings\n",
      "   ‚úÖ Created budget template: Studies\n",
      "   ‚úÖ Created budget template: Subscriptions\n",
      "   ‚úÖ Created budget template: Tech\n",
      "   ‚úÖ Created budget template: Transport\n",
      "   ‚úÖ Created budget template: Travel\n",
      "   ‚úÖ Created budget template: Venezuela\n",
      "‚úÖ Created 23 budget templates\n",
      "\n",
      "üìã FINAL IMPORT REPORT\n",
      "============================================================\n",
      "Import completed at: 2025-06-30 14:25:30.592212\n",
      "Database backup: personal_finance_backup_20250630_142529.db\n",
      "\n",
      "Import Results:\n",
      "\n",
      "Next steps:\n",
      "1. Test the web application with imported data\n",
      "2. Verify charts and analytics are working\n",
      "3. Check budget categories are properly populated\n",
      "4. Remove backup file if everything looks good\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELCACAZ\\AppData\\Local\\Temp\\ipykernel_1348\\10035739.py:95: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"\"\", (category, datetime.utcnow().isoformat(), datetime.utcnow().isoformat()))\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 8: VALIDATION AND REPORTING\n",
    "# =============================================================================\n",
    "\n",
    "def validate_import(conn):\n",
    "    \"\"\"Validate the imported data\"\"\"\n",
    "    print(\"\\n‚úÖ IMPORT VALIDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    validation_results = {}\n",
    "    \n",
    "    try:\n",
    "        # Check transaction counts\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM transactions\")\n",
    "        transaction_count = cursor.fetchone()[0]\n",
    "        print(f\"üìä Total transactions imported: {transaction_count}\")\n",
    "        \n",
    "        if transaction_count > 0:\n",
    "            # Check date range\n",
    "            cursor.execute(\"SELECT MIN(date), MAX(date) FROM transactions\")\n",
    "            date_range = cursor.fetchone()\n",
    "            print(f\"üìÖ Date range: {date_range[0]} to {date_range[1]}\")\n",
    "            \n",
    "            # Check categories\n",
    "            cursor.execute(\"SELECT COUNT(DISTINCT category) FROM transactions WHERE category IS NOT NULL\")\n",
    "            category_count = cursor.fetchone()[0]\n",
    "            print(f\"üìÇ Unique categories: {category_count}\")\n",
    "            \n",
    "            # Check owners\n",
    "            cursor.execute(\"SELECT COUNT(DISTINCT owner) FROM transactions WHERE owner IS NOT NULL\")\n",
    "            owner_count = cursor.fetchone()[0]\n",
    "            print(f\"üë• Unique owners: {owner_count}\")\n",
    "            \n",
    "            # Check for missing data\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM transactions WHERE description IS NULL OR description = ''\")\n",
    "            missing_descriptions = cursor.fetchone()[0]\n",
    "            print(f\"‚ö†Ô∏è Missing descriptions: {missing_descriptions}\")\n",
    "            \n",
    "            cursor.execute(\"SELECT COUNT(*) FROM transactions WHERE category IS NULL OR category = ''\")\n",
    "            missing_categories = cursor.fetchone()[0]\n",
    "            print(f\"‚ö†Ô∏è Missing categories: {missing_categories}\")\n",
    "            \n",
    "            # Sample data check\n",
    "            cursor.execute(\"SELECT * FROM transactions ORDER BY date DESC LIMIT 5\")\n",
    "            sample_data = cursor.fetchall()\n",
    "            print(f\"\\nüìã Sample imported data (latest 5 transactions):\")\n",
    "            for row in sample_data:\n",
    "                print(f\"   {row[2]} | {row[3]} | ${row[4]} | {row[6]}\")  # date, description, amount, category\n",
    "            \n",
    "            return {\n",
    "                'total_transactions': transaction_count,\n",
    "                'date_range': date_range,\n",
    "                'categories': category_count,\n",
    "                'owners': owner_count,\n",
    "                'missing_descriptions': missing_descriptions,\n",
    "                'missing_categories': missing_categories\n",
    "            }\n",
    "        else:\n",
    "            print(\"‚ùå No transactions found in database\")\n",
    "            return {'total_transactions': 0}\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error during validation: {e}\")\n",
    "        print(f\"‚ùå Error during validation: {e}\")\n",
    "        return {'error': str(e)}\n",
    "\n",
    "def populate_budget_templates(conn):\n",
    "    \"\"\"Populate budget templates from imported transaction categories\"\"\"\n",
    "    print(\"\\nüí∞ POPULATING BUDGET TEMPLATES\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        # Get unique categories from transactions\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT DISTINCT category \n",
    "            FROM transactions \n",
    "            WHERE category IS NOT NULL AND category != ''\n",
    "            ORDER BY category\n",
    "        \"\"\")\n",
    "        categories = cursor.fetchall()\n",
    "        \n",
    "        print(f\"üìÇ Found {len(categories)} unique categories\")\n",
    "        \n",
    "        # Insert budget templates\n",
    "        created_count = 0\n",
    "        for (category,) in categories:\n",
    "            try:\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO budget_templates \n",
    "                    (category, budget_amount, notes, is_active, created_at, updated_at)\n",
    "                    VALUES (?, 0.00, 'Auto-created from transaction data', 1, ?, ?)\n",
    "                \"\"\", (category, datetime.utcnow().isoformat(), datetime.utcnow().isoformat()))\n",
    "                \n",
    "                if cursor.rowcount > 0:\n",
    "                    created_count += 1\n",
    "                    print(f\"   ‚úÖ Created budget template: {category}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error creating budget template for {category}: {e}\")\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"‚úÖ Created {created_count} budget templates\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error populating budget templates: {e}\")\n",
    "        print(f\"‚ùå Error populating budget templates: {e}\")\n",
    "\n",
    "def generate_final_report():\n",
    "    \"\"\"Generate final import report\"\"\"\n",
    "    print(\"\\nüìã FINAL IMPORT REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Import completed at: {datetime.now()}\")\n",
    "    print(f\"Database backup: {backup_file}\")\n",
    "    print(\"\\nImport Results:\")\n",
    "    if 'import_results' in locals():\n",
    "        for table, results in import_results.items():\n",
    "            print(f\"  {table}: {results['imported']}/{results['total']} imported\")\n",
    "    \n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Test the web application with imported data\")\n",
    "    print(\"2. Verify charts and analytics are working\")\n",
    "    print(\"3. Check budget categories are properly populated\")\n",
    "    print(\"4. Remove backup file if everything looks good\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Run validation and final steps\n",
    "validation_results = validate_import(conn)\n",
    "populate_budget_templates(conn)\n",
    "generate_final_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15768ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 14:25:30,600 - INFO - ‚úÖ Database connection closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Import process completed successfully\n",
      "\n",
      "üéâ DATA IMPORT COMPLETED!\n",
      "Your personal finance database is now populated with all transaction data.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CLEANUP\n",
    "# =============================================================================\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Clean up resources\"\"\"\n",
    "    try:\n",
    "        conn.close()\n",
    "        logger.info(\"‚úÖ Database connection closed\")\n",
    "        print(\"‚úÖ Import process completed successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error during cleanup: {e}\")\n",
    "\n",
    "# Clean up\n",
    "cleanup()\n",
    "\n",
    "print(\"\\nüéâ DATA IMPORT COMPLETED!\")\n",
    "print(\"Your personal finance database is now populated with all transaction data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
